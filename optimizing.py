# -*- coding: utf-8 -*-
"""(git) Optimizing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FQmQzgCOgUZaWsa3qllqCEEj9rSA6lMV
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
import numpy as np
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential, Model
import cv2
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping
import os
from keras import layers
import keras
!pip install optuna

# Path to your dataset
dataset_path_train = "/content/drive/Shareddrives/Internship data sets/Training"
dataset_path_val = "/content/drive/Shareddrives/Internship data sets/Validation"


# Load the dataset
batch_size = 32
img_height = 256  # Change this to your image height
img_width = 256   # Change this to your image width
#training presets

train_ds = image_dataset_from_directory(
    dataset_path_train,
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

val_ds = image_dataset_from_directory(
    dataset_path_val,
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

"""Model 1"""

import optuna
import cv2
import numpy as np

class GaborFilterTuner:
    def __init__(self, train_ds, val_ds):
        self.train_ds = train_ds
        self.val_ds = val_ds

    def apply_gabor_filter(self, img, kernel_size, sigma, theta, lambda_, gamma, psi):
        # Apply Gabor filter to the image
        if img.ndim == 2:  # Check if the image is already grayscale
            img_gray = img
        else:  # Convert image to grayscale before applying the filter
            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        g_kernel = cv2.getGaborKernel(kernel_size, sigma, theta, lambda_, gamma, psi, ktype=cv2.CV_32F)
        filtered_img = cv2.filter2D(img_gray, -1, g_kernel)
        return filtered_img

    def objective(self, trial):
        kernel_size = trial.suggest_categorical('kernel_size', [(3, 3), (5, 5), (7, 7), (9, 9), (11, 11)])
        sigma = trial.suggest_float('sigma', 1.0, 10.0)
        theta = trial.suggest_categorical('theta', [0, 15, 30, 45, 60, 75, 90])
        lambda_ = trial.suggest_float('lambda_', 1.0, 10.0)
        gamma = trial.suggest_float('gamma', 0.5, 2.0)
        psi = trial.suggest_categorical('psi', [0, 15, 30, 45, 60, 75, 90])

        # Apply Gabor filter to the training and validation data
        X_train_pairs, y_train_pairs = [], []
        y_train_labels = []
        X_val_pairs, y_val_pairs = [], []
        all_images = []
        all_labels = []

        for batch in train_ds:
            images, labels = batch
            all_images.extend(images)
            all_labels.extend(labels)

        for i in range(len(all_images)):
            img_A_org, label_A = all_images[i], all_labels[i]
            img_A = self.apply_gabor_filter(img_A_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
            #print("A is: " ,all_labels[i])

            num = 0

            # Create pairs with other images
            for j in range(i, len(all_images)):
                img_B_org, label_B = all_images[j], all_labels[j]
                img_B = self.apply_gabor_filter(img_B_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
                #print("B is: " ,all_labels[j])
                if label_A == label_B:
                    new_label = 1  # same class, label is 1
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                else:
                    new_label = 0  # different class, label is 0

                    if num==0 or num==1 or num==2:
                      num+=1
                    elif num==3:
                      num-=3
                      X_train_pairs.append([img_A, img_B])
                      y_train_pairs.append(new_label)


        all_images = []
        all_labels = []

        for batch in val_ds:
            images, labels = batch
            all_images.extend(images)
            all_labels.extend(labels)

        for i in range(len(all_images)):
            img_A_org, label_A = all_images[i], all_labels[i]
            img_A = self.apply_gabor_filter(img_A_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)

            num=0

            # Create pairs with other images ( non-identical pairs )
            for j in range(i, len(all_images)):
                img_B_org, label_B = all_images[j], all_labels[j]
                img_B = self.apply_gabor_filter(img_B_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
                new_label = int(label_A == label_B)
                #print(new_label)
                if label_A == label_B:
                    new_label = 1  # same class, label is 1
                    X_val_pairs.append([img_B, img_A])
                    y_val_pairs.append(new_label)
                    X_val_pairs.append([img_B, img_A])
                    y_val_pairs.append(new_label)
                else:
                    new_label = 0  # different class, label is 0

                    if num==0 or num==1 or num==2:
                      num+=1
                    elif num==3:
                      num-=3
                      X_val_pairs.append([img_A, img_B])
                      y_val_pairs.append(new_label)


        X_train_pairs = np.array(X_train_pairs)
        y_train_pairs = np.array(y_train_pairs)
        X_val_pairs = np.array(X_val_pairs)
        y_val_pairs = np.array(y_val_pairs)

        X_train_pairs_A = X_train_pairs[:, 0, :, :]  # shape: (619, 256, 256)
        X_train_pairs_B = X_train_pairs[:, 1, :, :]  # shape: (619, 256, 256)
        X_val_pairs_A = X_val_pairs[:, 0, :, :]  # shape: (619, 256, 256)
        X_val_pairs_B = X_val_pairs[:, 1, :, :]  # shape: (619, 256, 256)

        # Create the network
        img_height = 256
        img_width = 256

        dim = 128
        chan = 4

        img_A_inp = Input((img_height, img_width, 1), name='img_A_inp')


        img_B_inp = Input((img_height, img_width, 1), name='img_B_inp')


        def get_cnn_block(depth, size):
                    return Sequential([
                        Conv2D(depth, size, 1, padding = 'same'),
                        BatchNormalization(),
                        Activation('relu'),
                        MaxPooling2D(),
                        Dropout(0.2)
        ])

        DEPTH = 32

        cnn1 = Sequential([
                        get_cnn_block(DEPTH, 7),
                        get_cnn_block(DEPTH*2, 5),
                        get_cnn_block(DEPTH*2, 5),
                        get_cnn_block(DEPTH*4, 3),
        ])

        feature_vector_A = cnn1(img_A_inp)

        feature_vector_B = cnn1(img_B_inp)

        cnn = Sequential([
          GlobalAveragePooling2D(),
          Flatten(),
          Dense(64, activation='relu'),
        ])

        concat = Concatenate()([feature_vector_A, feature_vector_B])

        concat_processed = cnn(concat)

        dense = Dense(64, activation='relu')(concat)
        output = Dense(2, activation='softmax')(dense)

        model = Model(inputs=[img_A_inp, img_B_inp], outputs=output)

        # Compile the model
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

        # Train the model
        model.fit([X_train_pairs_A, X_train_pairs_B], tf.keras.utils.to_categorical(y_train_pairs, num_classes=2), epochs=30, batch_size=8, verbose=0)

        # Evaluate the model
        y_pred = model.predict([X_val_pairs_A, X_val_pairs_B])
        y_pred_class = np.argmax(y_pred, axis=1)
        accuracy = np.mean(y_pred_class == y_val_pairs)

        return -accuracy

    def tune_hyperparameters(self, n_trials=50):
        study = optuna.create_study(direction='minimize', pruner=MedianPruner())
        study.optimize(self.objective, n_trials=n_trials)
        best_trial = study.best_trial
        best_params = best_trial.params
        best_accuracy = -best_trial.value
        return best_params, best_accuracy

from optuna.pruners import MedianPruner
# Set the verbosity level to INFO
optuna.logging.set_verbosity(optuna.logging.DEBUG)

# Create an instance of the GaborFilterTuner class
tuner = GaborFilterTuner(train_ds, val_ds)

# Tune the hyperparameters
best_params, best_accuracy = tuner.tune_hyperparameters(n_trials=20)

print("Best parameters:", best_params)
print("Best accuracy:", best_accuracy)

"""Model 2"""

import optuna
import cv2
import numpy as np

class GaborFilterTuner:
    def __init__(self, train_ds, val_ds):
        self.train_ds = train_ds
        self.val_ds = val_ds

    def apply_gabor_filter(self, img, kernel_size, sigma, theta, lambda_, gamma, psi):
        # Apply Gabor filter to the image
        if img.ndim == 2:  # Check if the image is already grayscale
            img_gray = img
        else:  # Convert image to grayscale before applying the filter
            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        g_kernel = cv2.getGaborKernel(kernel_size, sigma, theta, lambda_, gamma, psi, ktype=cv2.CV_32F)
        filtered_img = cv2.filter2D(img_gray, -1, g_kernel)
        return filtered_img

    def objective(self, trial):
        kernel_size = trial.suggest_categorical('kernel_size', [(3, 3), (5, 5), (7, 7), (9, 9), (11, 11)])
        sigma = trial.suggest_float('sigma', 1.0, 10.0)
        theta = trial.suggest_categorical('theta', [0, 15, 30, 45, 60, 75, 90])
        lambda_ = trial.suggest_float('lambda_', 1.0, 10.0)
        gamma = trial.suggest_float('gamma', 0.5, 2.0)
        psi = trial.suggest_categorical('psi', [0, 15, 30, 45, 60, 75, 90])

        # Apply Gabor filter to the training and validation data
        X_train_pairs, y_train_pairs = [], []
        y_train_labels = []
        X_val_pairs, y_val_pairs = [], []
        all_images = []
        all_labels = []

        for batch in train_ds:
            images, labels = batch
            all_images.extend(images)
            all_labels.extend(labels)

        for i in range(len(all_images)):
            img_A_org, label_A = all_images[i], all_labels[i]
            img_A = self.apply_gabor_filter(img_A_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
            #print("A is: " ,all_labels[i])

            num = 0

            # Create pairs with other images
            for j in range(i, len(all_images)):
                img_B_org, label_B = all_images[j], all_labels[j]
                img_B = self.apply_gabor_filter(img_B_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
                #print("B is: " ,all_labels[j])
                if label_A == label_B:
                    new_label = 1  # same class, label is 1
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                else:
                    new_label = 0  # different class, label is 0

                    if num==0 or num==1 or num==2:
                      num+=1
                    elif num==3:
                      num-=3
                      X_train_pairs.append([img_A, img_B])
                      y_train_pairs.append(new_label)


        all_images = []
        all_labels = []

        for batch in val_ds:
            images, labels = batch
            all_images.extend(images)
            all_labels.extend(labels)

        for i in range(len(all_images)):
            img_A_org, label_A = all_images[i], all_labels[i]
            img_A = self.apply_gabor_filter(img_A_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)

            num=0

            # Create pairs with other images ( non-identical pairs )
            for j in range(i, len(all_images)):
                img_B_org, label_B = all_images[j], all_labels[j]
                img_B = self.apply_gabor_filter(img_B_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
                new_label = int(label_A == label_B)
                #print(new_label)
                if label_A == label_B:
                    new_label = 1  # same class, label is 1
                    X_val_pairs.append([img_B, img_A])
                    y_val_pairs.append(new_label)
                    X_val_pairs.append([img_B, img_A])
                    y_val_pairs.append(new_label)
                else:
                    new_label = 0  # different class, label is 0

                    if num==0 or num==1 or num==2:
                      num+=1
                    elif num==3:
                      num-=3
                      X_val_pairs.append([img_A, img_B])
                      y_val_pairs.append(new_label)


        X_train_pairs = np.array(X_train_pairs)
        y_train_pairs = np.array(y_train_pairs)
        X_val_pairs = np.array(X_val_pairs)
        y_val_pairs = np.array(y_val_pairs)

        X_train_pairs_A = X_train_pairs[:, 0, :, :]  # shape: (619, 256, 256)
        X_train_pairs_B = X_train_pairs[:, 1, :, :]  # shape: (619, 256, 256)
        X_val_pairs_A = X_val_pairs[:, 0, :, :]  # shape: (619, 256, 256)
        X_val_pairs_B = X_val_pairs[:, 1, :, :]  # shape: (619, 256, 256)

        # Create the network
        img_height = 256
        img_width = 256
        dim = 128
        chan = 4

        img_A_inp = Input((img_height, img_width, 1), name='img_A_inp')
        img_A_reshaped = Reshape((dim, dim, chan))(img_A_inp)

        img_B_inp = Input((img_height, img_width, 1), name='img_B_inp')
        img_B_reshaped = Reshape((dim, dim, chan))(img_B_inp)

        def get_cnn_block(depth, size):
            return Sequential([
                Conv2D(depth, size, 1, padding='same'),
                BatchNormalization(),
                Activation('relu'),
                MaxPooling2D(),
                Dropout(0.2)
            ])

        DEPTH = 32

        cnn1 = Sequential([
            get_cnn_block(DEPTH, 3),
            get_cnn_block(DEPTH*2, 3),
            # MaxPooling2D(pool_size=(2, 2))
        ])
        cnn2 = Sequential([
            get_cnn_block(DEPTH, 5),
            get_cnn_block(DEPTH*2, 5),
            # MaxPooling2D(pool_size=(2, 2))
        ])
        cnn3 = Sequential([
            get_cnn_block(DEPTH, 7),
            get_cnn_block(DEPTH*2, 7),
            # MaxPooling2D(pool_size=(2, 2))
        ])

        feature_vector_A1 = cnn1(img_A_reshaped)
        feature_vector_A2 = cnn2(img_A_reshaped)
        feature_vector_A3 = cnn3(img_A_reshaped)

        feature_vector_A = Concatenate()([feature_vector_A1, feature_vector_A2, feature_vector_A3])

        feature_vector_B1 = cnn1(img_B_reshaped)
        feature_vector_B2 = cnn2(img_B_reshaped)
        feature_vector_B3 = cnn3(img_B_reshaped)

        feature_vector_B = Concatenate()([feature_vector_B1, feature_vector_B2, feature_vector_B3])

        cnn = Sequential([
            GlobalAveragePooling2D(),
            Flatten(),
            Dense(64, activation='relu'),
        ])

        feature_vector_A = cnn(feature_vector_A)
        feature_vector_B = cnn(feature_vector_B)

        concat = Concatenate()([feature_vector_A, feature_vector_B])

        dense = Dense(64, activation='relu')(concat)
        output = Dense(2, activation='softmax')(dense)

        model = Model(inputs=[img_A_inp, img_B_inp], outputs=output)

        # Compile the model
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

        # Train the model
        model.fit([X_train_pairs_A, X_train_pairs_B], tf.keras.utils.to_categorical(y_train_pairs, num_classes=2), epochs=30, batch_size=8, verbose=0)

        # Evaluate the model
        y_pred = model.predict([X_val_pairs_A, X_val_pairs_B])
        y_pred_class = np.argmax(y_pred, axis=1)
        accuracy = np.mean(y_pred_class == y_val_pairs)

        return -accuracy

    def tune_hyperparameters(self, n_trials=50):
        study = optuna.create_study(direction='minimize', pruner=MedianPruner())
        study.optimize(self.objective, n_trials=n_trials)
        best_trial = study.best_trial
        best_params = best_trial.params
        best_accuracy = -best_trial.value
        return best_params, best_accuracy

from optuna.pruners import MedianPruner
# Set the verbosity level to INFO
optuna.logging.set_verbosity(optuna.logging.DEBUG)

# Create an instance of the GaborFilterTuner class
tuner = GaborFilterTuner(train_ds, val_ds)

# Tune the hyperparameters
best_params, best_accuracy = tuner.tune_hyperparameters(n_trials=20)

print("Best parameters:", best_params)
print("Best accuracy:", best_accuracy)

"""Model 3"""

import optuna
import cv2
import numpy as np

class GaborFilterTuner:
    def __init__(self, train_ds, val_ds):
        self.train_ds = train_ds
        self.val_ds = val_ds

    def apply_gabor_filter(self, img, kernel_size, sigma, theta, lambda_, gamma, psi):
        # Apply Gabor filter to the image
        if img.ndim == 2:  # Check if the image is already grayscale
            img_gray = img
        else:  # Convert image to grayscale before applying the filter
            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        g_kernel = cv2.getGaborKernel(kernel_size, sigma, theta, lambda_, gamma, psi, ktype=cv2.CV_32F)
        filtered_img = cv2.filter2D(img_gray, -1, g_kernel)
        return filtered_img

    def objective(self, trial):
        kernel_size = trial.suggest_categorical('kernel_size', [(3, 3), (5, 5), (7, 7), (9, 9), (11, 11)])
        sigma = trial.suggest_float('sigma', 1.0, 10.0)
        theta = trial.suggest_categorical('theta', [0, 15, 30, 45, 60, 75, 90])
        lambda_ = trial.suggest_float('lambda_', 1.0, 10.0)
        gamma = trial.suggest_float('gamma', 0.5, 2.0)
        psi = trial.suggest_categorical('psi', [0, 15, 30, 45, 60, 75, 90])

        X_train_pairs, y_train_pairs = [], []
        y_train_labels = []
        X_val_pairs, y_val_pairs = [], []
        all_images = []
        all_labels = []

        for batch in train_ds:
            images, labels = batch
            all_images.extend(images)
            all_labels.extend(labels)

        for i in range(len(all_images)):
            img_A_org, label_A = all_images[i], all_labels[i]
            #img_A = enhance_contrast(img_A_org.numpy())
            img_A = self.apply_gabor_filter(img_A_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
            #print("A is: " ,all_labels[i])

            num = 0

            # Create pairs with other images
            for j in range(i, len(all_images)):
                img_B_org, label_B = all_images[j], all_labels[j]
                img_B = self.apply_gabor_filter(img_B_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)
                #print("B is: " ,all_labels[j])
                if label_A == label_B:
                    new_label = 1  # same class, label is 1
                    X_train_pairs.append([img_B, img_A])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)
                    X_train_pairs.append([img_A, img_B])
                    y_train_pairs.append(new_label)

                else:
                    new_label = 0  # different class, label is 0

                    if num==0 or num==1 or num==2:
                      num+=1
                    elif num==3:
                      num-=3
                      X_train_pairs.append([img_A, img_B])
                      y_train_pairs.append(new_label)


        all_images = []
        all_labels = []

        for batch in val_ds:
            images, labels = batch
            all_images.extend(images)
            all_labels.extend(labels)

        for i in range(len(all_images)):
            img_A_org, label_A = all_images[i], all_labels[i]
            img_A = self.apply_gabor_filter(img_A_org.numpy(), kernel_size, sigma, theta, lambda_, gamma, psi)

            num=0

            # Create pairs with other images ( non-identical pairs )
            for j in range(i, len(all_images)):
                img_B_org, label_B = all_images[j], all_labels[j]
                img_B = self.apply_gabor_filter(img_B_org.numpy(),kernel_size, sigma, theta, lambda_, gamma, psi)
                new_label = int(label_A == label_B)
                #print(new_label)
                if label_A == label_B:
                    new_label = 1  # same class, label is 1
                    X_val_pairs.append([img_B, img_A])
                    y_val_pairs.append(new_label)
                    X_val_pairs.append([img_B, img_A])
                    y_val_pairs.append(new_label)
                else:
                    new_label = 0  # different class, label is 0

                    if num==0 or num==1 or num==2:
                      num+=1
                    elif num==3:
                      num-=3
                      X_val_pairs.append([img_A, img_B])
                      y_val_pairs.append(new_label)

        X_train_pairs = np.array(X_train_pairs)
        y_train_pairs = np.array(y_train_pairs)
        X_val_pairs = np.array(X_val_pairs)
        y_val_pairs = np.array(y_val_pairs)

        X_train_pairs_A = X_train_pairs[:, 0, :, :]  # shape: (619, 256, 256)
        X_train_pairs_B = X_train_pairs[:, 1, :, :]  # shape: (619, 256, 256)
        X_val_pairs_A = X_val_pairs[:, 0, :, :]  # shape: (619, 256, 256)
        X_val_pairs_B = X_val_pairs[:, 1, :, :]  # shape: (619, 256, 256)

        # Create the network
        img_height = 256
        img_width = 256
        dim = 128
        chan = 4

        img_A_inp = Input((img_height, img_width, 1), name='img_A_inp')
        img_A_reshaped = Reshape((dim, dim, chan))(img_A_inp)

        img_B_inp = Input((img_height, img_width, 1), name='img_B_inp')
        img_B_reshaped = Reshape((dim, dim, chan))(img_B_inp)

        def get_cnn_block(depth):
            return Sequential([
                Conv2D(depth, 1, padding='same'),
                BatchNormalization(),
                Activation('relu'),
                MaxPooling2D(),
                Dropout(0.2)
            ])

        DEPTH = 32
        cnn = Sequential([
            #data_augmentation,
            get_cnn_block(DEPTH),
            get_cnn_block(DEPTH*2),
            get_cnn_block(DEPTH*4),
            get_cnn_block(DEPTH*8),
            GlobalAveragePooling2D(),
            Flatten(),
            Dense(64, activation='relu')
        ])

        feature_vector_A = cnn(img_A_inp)
        feature_vector_B = cnn(img_B_inp)

        concat = Concatenate()([feature_vector_A, feature_vector_B])

        dense = Dense(64, activation='relu')(concat)
        output = Dense(2, activation='softmax')(dense)

        model = Model(inputs=[img_A_inp, img_B_inp], outputs=output)

        # Compile the model
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

        # Train the model
        model.fit([X_train_pairs_A, X_train_pairs_B], tf.keras.utils.to_categorical(y_train_pairs, num_classes=2), epochs=30, batch_size=8, verbose=0)

        # Evaluate the model
        y_pred = model.predict([X_val_pairs_A, X_val_pairs_B])
        y_pred_class = np.argmax(y_pred, axis=1)
        accuracy = np.mean(y_pred_class == y_val_pairs)

        return -accuracy

    def tune_hyperparameters(self, n_trials=50):
        study = optuna.create_study(direction='minimize', pruner=MedianPruner())
        study.optimize(self.objective, n_trials=n_trials)
        best_trial = study.best_trial
        best_params = best_trial.params
        best_accuracy = -best_trial.value
        return best_params, best_accuracy

from optuna.pruners import MedianPruner
# Set the verbosity level to INFO
optuna.logging.set_verbosity(optuna.logging.DEBUG)

# Create an instance of the GaborFilterTuner class
tuner = GaborFilterTuner(train_ds, val_ds)

# Tune the hyperparameters
best_params, best_accuracy = tuner.tune_hyperparameters(n_trials=20)

print("Best parameters:", best_params)
print("Best accuracy:", best_accuracy)
